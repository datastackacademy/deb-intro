# Course Overview

- ## [Ch. 1: Introduction to Python and Pandas](ch1/)

    This chapter will be taught over two weeks, and will introduce you (in week one) to programming in Python, and (in week two), to Pandas, a very powerful Python library used for data analysis. 

    ### Week 1 (Python)

    - [Ep. 1: Python Introduction](ch1/ep1/)
    - [Ep. 2: Python Loops and Iterators](ch1/ep2/)
    - [Ep. 3: Python advanced functions and classes](ch1/ep3/)
    - [Ep. 4: Additional Python Practice](ch1/ep4/)
    - Ep. 5: Assessment

    ### Week 2 (Pandas)

    - [Ep. 1: Pandas Introduction](ch1/ep6/)
    - [Ep. 2: Exploring Data with Pandas](ch1/ep7/)
    - [Ep. 3: GROUPing and JOINing data](ch1/ep8/)
    - [Ep. 4: Data Cleaning](ch1/ep9/)
    - Ep. 5: Assessment


- ## [Ch. 2: Databases](ch2/)

    Chapter 2 introduces the basics of working with relational databases, Structured Query Language (SQL), and how to work with databases in Python.

    - [Ep. 1: Intro to SQL](ch2/ep1/)
    - [Ep. 2: Advanced SELECT](ch2/ep2/)
    - [Ep. 3: GROUP BY](ch2/ep3/)
    - [Ep. 4: Joins](ch2/ep4/)
    - [Ep. 5: Python and DBs](ch2/ep5/)
    - Ep. 6: Assessment

- ## [Ch. 3: The Tura-Air Datasets](ch3/)
    ### Week 1

    In the first part of chapter three, you get your first look at the data that we will use for the rest of the course, and will have a chance to use the Python and Pandas skills you have already learned to explore and work with that data.

    - [Ep. 1: Introduction to Tura-Air](ch3/ep1/)
    - [Ep. 2: Database Creation, Writing, and Logging](ch3/ep2/)
    - [Ep. 3: Merging Data](ch3/ep3/)
    - [Ep. 4: Buffer and Review](ch3/ep4/)
    - Ep. 5: Assessment

    ### Week 2

    In the second part of this chapter, we will introduce Google Cloud Platform (GCP) and, in particular, BigQuery, GCP's big data analytics engine.

    - [Ep. 1: Google Cloud intro](ch3/ep6/)
    - [Ep. 2: BigQuery Deep Dive](ch3/ep7/)
    - [Ep. 3: Writing to BigQuery](ch3/ep8/)
    - [Ep. 4: Reading from BigQuery](ch3/ep9/)
    - Ep. 5: Assessment

- ## [Ch. 4: APIs](ch4/)

    In chapter four, you will learn to work with Application Programming Interfaces (APIs), which are they key to connecting your software to other products and services with the greatest degree of flexibility, simplicity, safety, and control.

    - [Ep. 1: Intro to APIs](ch4/ep1/)
    - [Ep. 2: Creating an API](ch4/ep2/)
    - [Ep. 3: Improving our API](ch4/ep3/)
    - [Ep. 4: GCP AppEngine](ch4/ep4/)
    - Ep. 5: Assessment


- ## [Ch. 5: Docker](ch5/)

    In chapter five, you will learn to work with containerization using Docker. Containers have become standard practice in software and data engineering, because they allow us to package our code along with dependencies so that it is easily portable between platforms.

    - [Ep. 1: Basic Docker CLI & Dockerfile](ch5ep1/)
    - [Ep. 2: Advanced Dockerfile](ch5/ep2/)
    - [Ep. 3: Docker-compose](ch5/ep3/)
    - [Ep. 4: GCP Cloud Run](ch5/ep4/)
    - Ep. 5: Assessment

- ## [Ch. 6: Apache Airflow](ch6/)

    Chapter 6 teaches you how to use Apache Airflow, an open-source platform used to programatically program, schedule, and monitor workflows. It also introduces GCP Cloud Composer, Google's cloud service based on Airflow. 
    
    - [Ep. 1: Intro to Airflow](ch6/ep1/)
    - [Ep. 2: Automate with Airflow](ch6/ep2/)
    - [Ep. 3: Airflow Advanced Topics](ch6/ep3/)
    - [Ep. 4: Buffer](ch6/ep4/)
    - [Ep. 5: Cloud Composer](ch6/ep5/)
    - Ep. 6: Assessment

- ## [Ch. 7: Spark](ch7/)

    Chapter 7, another two-week chapter, will teach you how to use Apache Spark, an open-source, distributed processing system for big data workloads.  

    In the first week, we introduce Spark, its data structures, and using SQL with Spark.
    ### Week 1 (Spark)

    - [Ep. 1: Intro to Spark and RDD](ch7/ep1/)
    - [Ep. 2: ABCs of Spark SQL and DataFrames](ch7/ep2/)
    - [Ep. 3: Spark SQL](ch7/ep3/)
    - [Ep. 4: Spark SQL cont.](ch7/ep4/)
    - Ep. 5: Assessment

    Week 2 deals with Python\Spark interfacing and running Spark on the cloud.
    ### Week 2 (More on Spark)

    - [Ep. 6: Ingesting Flight Data with PySpark](ch7/ep6/)
    - [Ep. 7: GCP Dataproc and BigQuery](ch7/ep7/)
    - [Ep. 8: Spark Notebooks and Visualization](ch7/ep8/)
    - [Ep. 9: Airflow and Dataproc](ch7/ep9/)
    - Ep. 10: Assessment

- ## [Ch. 8: Serverless Architecture](ch8/)

    Chapter 8 introduces serverless architecture (a key component of the cloud development paradigm) and the details of pipeline implementation with Google Cloud Functions and Cloud Workflow.

    - [Ep. 1: Serverless and Cloud Functions intro](ch8/ep1/)
    - [Ep. 2: Cloud Function Pipeline Batch](ch8/ep2/)
    - [Ep. 3: Serverless Orchestration - Google Cloud Workflow](ch8/ep3/)
    - [Ep. 4: Misc.](ch8/ep4/)
    - Ep. 5: Assessment

- ## [Ch. 9: Streaming (Pub/Sub + Spark)](ch9/)

   Chapter 9 deals with streaming data with Cloud Pub/Sub, Cloud Functions, and BigTable.

    - [Ep. 1: Pub/Sub intro](ch9/ep1/)
    - [Ep. 2: Streaming Trips with Functions](ch9/ep2/)
    - [Ep. 3: Streaming Trips with Functions cont.](ch9/ep3/)
    - [Ep. 4: Streaming Trips with Functions and BigTable](ch9/ep4/)
    - Ep. 5: Assessment

## [Ch. 10: Data Visualization](ch10/)

    In Chapter 10 we take a look at techniques for visualizing data.

    - [Ep. 1: Data Studio intro](ch10/ep1/)
    - [Ep. 2: Filters and Trends](ch10/ep2/)
    - [Ep. 3: Geoplots](ch10/ep3/)
    - [Ep. 4: Challenge](ch10/ep4/)
    - Ep. 5: Assessment